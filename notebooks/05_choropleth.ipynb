{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-factory",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-halloween",
   "metadata": {},
   "source": [
    "# Choropleth Mapping\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-sauce",
   "metadata": {},
   "source": [
    "Choropleths are geographic maps that display statistical information encoded \n",
    "in a color palette. Choropleth maps play a prominent role in geographic data science as they allow\n",
    "us to display non-geographic attributes or variables on a geographic map. The\n",
    "word choropleth stems from the root \"choro\", meaning \"region\". \n",
    "Choropleth maps represent data at the region level, and are appropriate for\n",
    "areal unit data where each observation combines a value of an attribute and a\n",
    "geometric figure, usually a polygon. Choropleth maps derive from an earlier era\n",
    "where cartographers faced technological constraints that precluded the use of\n",
    "unclassed maps where each unique attribute value could be represented by a\n",
    "distinct symbol or color. Instead, attribute values were grouped into a smaller\n",
    "number of classes, usually not more than 12. Each class was associated with a\n",
    "unique symbol that was in turn applied to all observations with attribute values\n",
    "falling in the class.\n",
    "\n",
    "Although today these technological constraints are no longer binding, and\n",
    "unclassed mapping is feasible, there are still good reasons for adopting a\n",
    "classed approach. Chief among these is to reduce the cognitive load involved in\n",
    "parsing the complexity of an unclassed map. A choropleth map reduces this\n",
    "complexity by drawing upon statistical and visualization theory to provide an\n",
    "effective representation of the spatial distribution of the attribute values\n",
    "across the areal units. \n",
    "\n",
    "## Principles\n",
    "\n",
    "The effectiveness of a choropleth map depends largely on the purpose of the map.\n",
    "Which message you want to communicate will shape what options are preferable\n",
    "over others. In this chapter we consider three dimensions over which putting\n",
    "intentional thinking will pay off. Choropleth mapping thus revolves around: first,\n",
    "selecting a number of groups smaller than $n$ into which all values in our dataset \n",
    "will be mapped to; second, identifying a classification algorithm that executes such\n",
    "mapping, following some principle that is aligned with our interest; and third, once\n",
    "we know into how many groups we are going to reduce all values in our data, which\n",
    "color is assigned to each group to ensure it encodes the information we want to reflect.\n",
    "In broad terms, the classification scheme\n",
    "defines the number of classes as well as the rules for assignment; while a good\n",
    "symbolization conveys information about the value differentiation across\n",
    "classes.\n",
    "\n",
    "In this chapter we first discuss the approaches used to classify attribute\n",
    "values. This is followed by a (brief) overview of color theory and the implications of\n",
    "different color schemes for effective map design. We combine theory and practice\n",
    "by exploring how these concepts are implemented in different Python packages,\n",
    "including `geopandas`, and the Pysal federation of packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-blocking",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "import pandas\n",
    "import geopandas\n",
    "import pysal\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-document",
   "metadata": {},
   "source": [
    "## Quantitative data classification \n",
    "\n",
    "Selecting the number of groups into which we want to assign the values in our data,\n",
    "and how each value is assigned into a group can be seen as a classification problem.\n",
    "Data classification considers the problem of \n",
    "partitioning the attribute values into mutually exclusive and exhaustive\n",
    "groups. The precise manner in which this is done will be a function of the\n",
    "measurement scale of the attribute in question. For quantitative attributes\n",
    "(ordinal, interval, ratio scales), the classes will have an explicit ordering.\n",
    "More formally, the classification problem is to define class boundaries such\n",
    "that\n",
    "\n",
    "$$\n",
    "c_j < y_i \\le  c_{j+1} \\ \\forall y_i \\in C_{j}\n",
    "$$\n",
    "\n",
    "where $y_i$ is the\n",
    "value of the attribute for spatial location $i$, $j$ is a class index, and $c_j$\n",
    "represents the lower bound of interval $j$. Different classification schemes obtain from their definition of the class\n",
    "boundaries. The choice of the classification scheme should take into\n",
    "consideration the statistical distribution of the attribute values as well\n",
    "as the goal of our map (e.g., highlight outliers vs. accurately depict the distribution of values).\n",
    "\n",
    "To illustrate these considerations, we will examine regional income data for 32 Mexican states {cite}`Rey_2010` in this chapter. The variable we focus on is per capita gross domestic product\n",
    "for 1940 (`PCGDP1940`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-superior",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mx = geopandas.read_file(\"../data/mexico/mexicojoin.shp\")\n",
    "mx[[\"NAME\", \"PCGDP1940\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-compiler",
   "metadata": {},
   "source": [
    "Which displays the following statistical distribution (in Figure 1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-customer",
   "metadata": {
    "caption": "Distribution of per capita GDP across 1940s Mexican states",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot histogram\n",
    "ax = seaborn.histplot(mx[\"PCGDP1940\"], bins=5)\n",
    "# Add rug on horizontal axis\n",
    "seaborn.rugplot(mx[\"PCGDP1940\"], height=0.05, color=\"red\", ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-mattress",
   "metadata": {},
   "source": [
    "As we can see, the distribution is positively skewed as is common in regional income studies. In other words,\n",
    "the mean exceeds the median (`50%`, in the table below), leading to the long right tail in the figure. As\n",
    "we shall see, this skewness will have implications for the choice of choropleth\n",
    "classification scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-letter",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "mx[\"PCGDP1940\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-farmer",
   "metadata": {},
   "source": [
    "For quantitative attributes we first sort the data by their value,\n",
    "such that $x_0 \\le x_2 \\ldots \\le x_{n-1}$. For a prespecified number of classes\n",
    "$k$, the classification problem boils down to selecting $k-1$ break points\n",
    "along the sorted values that separate the values into mutually exclusive and\n",
    "exhaustive groups.\n",
    "\n",
    "In fact, the determination of the histogram above can\n",
    "be viewed as one approach to this selection.\n",
    "The method `seaborn.histplot` uses the matplotlib `hist`\n",
    "function under the hood to determine the class boundaries and the counts of\n",
    "observations in each class. In the figure, we have five classes which can be\n",
    "extracted with an explicit call to the `hist` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, bins, patches = ax.hist(mx[\"PCGDP1940\"], bins=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-forest",
   "metadata": {},
   "source": [
    "The `counts` object captures how many observations each category in the classification has:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-gauge",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-organic",
   "metadata": {},
   "source": [
    "The `bin` object stores these break points we are interested in when considering classification schemes (the `patches` object can be ignored in this context, as it stores the geometries of the histogram plot):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-wichita",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-remove",
   "metadata": {},
   "source": [
    "This yields five bins, with the first having a lower bound of 1892 and an upper\n",
    "bound of 5985.8 which contains 17 observations. The determination of the\n",
    "interval width ($w$) and the number of bins in `seaborn` is based on the Freedman-Diaconis rule {cite}`freedman1981histogram`:\n",
    "\n",
    "$$\n",
    "w = 2 * IQR * n^{-1/3}\n",
    "$$\n",
    "\n",
    "where $IQR$ is the inter quartile\n",
    "range of the attribute values. Given $w$, the number of bins ($k$) is:\n",
    "\n",
    "$$k = \\dfrac{(max-min)}{w}$$\n",
    "\n",
    "The choropleth literature has many alternative classification algorithms that follow criteria that can be of interest in different contexts, as they focus on different priorities. Below, we will focus on a few of them. To compute the classification, we will rely on the `mapclassify` package of the Pysal family:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-schedule",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mapclassify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-luxury",
   "metadata": {},
   "source": [
    "### Equal intervals\n",
    "\n",
    "The Freedman-Diaconis approach provides a rule to determine the width and, in\n",
    "turn, the number of bins for the classification. This is a special case of a\n",
    "more general classifier known as \"equal intervals\", where each of the bins has\n",
    "the same width in the value space. For a given value of $k$, equal intervals\n",
    "classification splits the range of the attribute space into $k$ equal length\n",
    "intervals, with each interval having a width $w = \\frac{x_0 - x_{n-1}}{k}$. Thus\n",
    "the maximum class is $(x_{n-1}-w, x_{n-1}]$ and the first class is $(-\\infty,\n",
    "x_{n-1} - (k-1)w]$.\n",
    "\n",
    "Equal intervals have the dual advantages of simplicity and ease of\n",
    "interpretation. However, this rule only considers the extreme values of the\n",
    "distribution and, in some cases, this can result in one or more classes being\n",
    "sparse. This is clearly the case in our income dataset, as the majority of the\n",
    "values are placed into the first two classes leaving the last three classes\n",
    "rather sparse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-bachelor",
   "metadata": {},
   "outputs": [],
   "source": [
    "ei5 = mapclassify.EqualInterval(mx[\"PCGDP1940\"], k=5)\n",
    "ei5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-values",
   "metadata": {},
   "source": [
    " Note that each of the intervals, however, has equal width of\n",
    "$w=4093.8$. It should also be noted that the first class is closed on the lower bound,\n",
    "in contrast to the general approach defined above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-brain",
   "metadata": {},
   "source": [
    "### Quantiles\n",
    "To avoid the potential problem of sparse classes, the quantiles of\n",
    "the distribution can be used to identify the class boundaries. Indeed, each\n",
    "class will have approximately $\\mid\\frac{n}{k}\\mid$ observations using the quantile\n",
    "classifier. If $k=5$ the sample quintiles are used to define the upper limits of\n",
    "each class resulting in the following classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-approach",
   "metadata": {},
   "outputs": [],
   "source": [
    "q5 = mapclassify.Quantiles(mx.PCGDP1940, k=5)\n",
    "q5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-fleet",
   "metadata": {},
   "source": [
    "Note that while the numbers of values in each class are roughly equal, the\n",
    "widths of the first four intervals are rather different:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-frederick",
   "metadata": {},
   "outputs": [],
   "source": [
    "q5.bins[1:] - q5.bins[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logical-pleasure",
   "metadata": {},
   "source": [
    "While quantile classification avoids the pitfall of sparse classes, this classification is\n",
    "not problem-free. The varying widths of the intervals can be markedly different\n",
    "which can lead to problems of interpretation. A second challenge facing quantiles\n",
    "arises when there are a large number of duplicate values in the distribution\n",
    "such that the limits for one or more classes become ambiguous. For example, if one had a variable with $n=20$ but 10 of the observations took on the same value which was the minimum observed, then for values of $k>2$, the class boundaries become ill-defined since a simple rule of splitting at the $n/k$ ranked observed value would depend upon how ties are treated when ranking.\n",
    "\n",
    "Let us generate a synthetic variable with these characteristics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "numpy.random.seed(12345)\n",
    "# Generate a variable of 20 values randomly\n",
    "# selected from 0 to 10\n",
    "x = numpy.random.randint(0, 10, 20)\n",
    "# Manually ensure the first ten values are 0 (the\n",
    "# minimum value)\n",
    "x[0:10] = x.min()\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-least",
   "metadata": {},
   "source": [
    "And we will now run quantile classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-string",
   "metadata": {},
   "outputs": [],
   "source": [
    "ties = mapclassify.Quantiles(x, k=5)\n",
    "ties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-affair",
   "metadata": {},
   "source": [
    "For clarity, the unique values in our dataset are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-mailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "ux = numpy.unique(x)\n",
    "ux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-convenience",
   "metadata": {},
   "source": [
    "In this case, `mapclassify` will issue a warning alerting the user to the issue that this sample does not contain enough unique values to form \n",
    "the number of well-defined classes requested.  It then forms a lower number of classes using pseudo-quantiles, or quantiles defined on the unique values in the sample, and then uses the pseudo-quantiles to classify all the values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-combination",
   "metadata": {},
   "source": [
    "### Mean-standard deviation\n",
    "\n",
    "Our third classifier uses the sample mean $\\bar{x} =\n",
    "\\frac{1}{n} \\sum_{i=1}^n x_i$ and sample standard deviation $s = \\sqrt{\n",
    "\\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})  }$ to define class boundaries as\n",
    "some distance from the sample mean, with the distance being a multiple of the\n",
    "standard deviation. For example, a common definition for $k=5$ is to set the\n",
    "upper limit of the first class to two standard deviations ($c_{0}^u = \\bar{x} - 2 s$), and the intermediate\n",
    "classes to have upper limits within one standard deviation ($c_{1}^u = \\bar{x}-s,\\ c_{2}^u = \\bar{x}+s, \\ c_{3}^u\n",
    "= \\bar{x}+2s$). Any values greater (smaller) than two standard deviations above (below) the mean\n",
    "are placed into the top (bottom) class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "msd = mapclassify.StdMean(mx[\"PCGDP1940\"])\n",
    "msd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-hughes",
   "metadata": {},
   "source": [
    "This classifier is best used when data is normally distributed or, at least, when the sample mean is a meaningful measure to anchor the classification around. Clearly this is\n",
    "not the case for our income data as the positive skew results in a loss of\n",
    "information when we use the standard deviation. The lack of symmetry leads to\n",
    "an inadmissible upper bound for the first  class as well as a concentration of the\n",
    "vast majority of values in the middle class.\n",
    "\n",
    "### Maximum breaks\n",
    "\n",
    "The maximum breaks classifier decides where to set the break points between\n",
    "classes by considering the difference between sorted values. That is, rather\n",
    "than considering a value of the dataset in itself, it looks at how apart each\n",
    "value is from the next one in the sorted sequence. The classifier then places\n",
    "the $k-1$ break points in between the pairs of values most stretched apart from\n",
    "each other in the entire sequence, proceeding in descending order relative to\n",
    "the size of the breaks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-static",
   "metadata": {},
   "outputs": [],
   "source": [
    "mb5 = mapclassify.MaximumBreaks(mx[\"PCGDP1940\"], k=5)\n",
    "mb5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-divorce",
   "metadata": {},
   "source": [
    "Maximum breaks is an appropriate approach when we are interested in making sure\n",
    "observations in each class are separated from those in neighboring classes. As\n",
    "such, it works well in cases where the distribution of values is not unimodal.\n",
    "In addition, the algorithm is relatively fast to compute. However, its\n",
    "simplicity can sometimes cause unexpected results. To the extent that maximum breaks classification only\n",
    "considers the top $k-1$ differences between consecutive values, other more nuanced\n",
    "within-group differences and dissimilarities can be ignored.\n",
    "\n",
    "### Boxplot\n",
    "\n",
    "The boxplot classification is a blend of the quantile and\n",
    "standard deviation classifiers. Here $k$ is predefined to six, with the upper limit of the first class set\n",
    "to:\n",
    "\n",
    "$$q_{0.25}-h \\, IQR$$\n",
    "\n",
    "where $IQR = q_{0.75}-q_{0.25}$ is the\n",
    "inter-quartile range; and $h$ corresponds to the hinge, or the multiplier of the $IQR$ to obtain the bounds of the \"whiskers\" from a box-and-whisker plot of the data. The lower limit of the sixth class is set to $q_{0.75}+h \\,\n",
    "IQR$. Intermediate classes have their upper limits set to the 0.25, 0.50 and\n",
    "0.75 percentiles of the attribute values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-publisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "bp = mapclassify.BoxPlot(mx[\"PCGDP1940\"])\n",
    "bp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-sussex",
   "metadata": {},
   "source": [
    "Any values falling into either of the extreme classes are defined as outliers.\n",
    "Note that because the income values are non-negative by definition, the lower\n",
    "outlier class has an inadmissible upper bound meaning that lower outliers would\n",
    "not be possible for this sample.\n",
    "\n",
    "The default value for the hinge is $h=1.5$ in\n",
    "`mapclassify`. However, this can be specified by the user for an alternative classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-japan",
   "metadata": {},
   "outputs": [],
   "source": [
    "bp1 = mapclassify.BoxPlot(mx[\"PCGDP1940\"], hinge=1)\n",
    "bp1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-criterion",
   "metadata": {},
   "source": [
    "Doing so will affect the definition of the outlier classes, as well as the\n",
    "neighboring internal classes.\n",
    "\n",
    "### Head-tail breaks\n",
    "\n",
    "The head tail algorithm {cite}`Jiang_2013` is based on a recursive partitioning of the data using splits around\n",
    "iterative means. The splitting process continues until the distributions within each of\n",
    "the classes no longer display a heavy-tailed distribution in the sense that\n",
    "there is a balance between the number of smaller and larger values assigned to\n",
    "each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-tactics",
   "metadata": {},
   "outputs": [],
   "source": [
    "ht = mapclassify.HeadTailBreaks(mx[\"PCGDP1940\"])\n",
    "ht"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-importance",
   "metadata": {},
   "source": [
    "For data with a heavy-tailed distribution, such as power law and log normal\n",
    "distributions, the head tail breaks classifier  can be particularly\n",
    "effective.\n",
    "\n",
    "### Jenks-Caspall breaks\n",
    "\n",
    "This approach, as well as the following two, tackles the classification\n",
    "challenge from a heuristic perspective, rather than from a deterministic one.\n",
    "Originally proposed by {cite}`Jenks_1971`, the Jenks-Caspall classification algorithm\n",
    "aims to minimize\n",
    "the sum of absolute deviations around class means. The approach begins with a\n",
    "prespecified number of classes and an arbitrary initial set of class breaks -\n",
    "for example using quintiles. The algorithm attempts to improve the objective\n",
    "function by considering the movement of observations between adjacent classes.\n",
    "For example, the largest value in the lowest quintile would be considered for\n",
    "movement into the second quintile, while the lowest value in the second\n",
    "quintile would be considered for a possible move into the first quintile. The\n",
    "candidate move resulting in the largest reduction in the objective function\n",
    "would be made, and the process continues until no other improving moves are\n",
    "possible. The Jenks-Caspall algorithm is the one-dimension case of the widely\n",
    "used K-Means algorithm for clustering, which we will see later in this book\n",
    "when we consider [Clustering and Regionalization](10_clustering_and_regionalization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-chocolate",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(12345)\n",
    "jc5 = mapclassify.JenksCaspall(mx[\"PCGDP1940\"], k=5)\n",
    "jc5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-ordinance",
   "metadata": {},
   "source": [
    "### Fisher-Jenks breaks\n",
    "\n",
    "The second optimal algorithm adopts a dynamic programming approach to minimize\n",
    "the sum of the absolute deviations around class medians. In contrast to the\n",
    "Jenks-Caspall algorithm, the Fisher-Jenks alorithm is guaranteed to produce an optimal\n",
    "classification for a prespecified number of classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-track",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(12345)\n",
    "fj5 = mapclassify.FisherJenks(mx[\"PCGDP1940\"], k=5)\n",
    "fj5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-communist",
   "metadata": {},
   "source": [
    "### Max-p\n",
    "\n",
    "Finally, the max-p classifier adopts the algorithm underlying the max-p region\n",
    "building method {cite}`Duque_2011` to the case of map classification. It is similar in spirit to\n",
    "Jenks-Caspall in that it considers greedy swapping between adjacent classes to\n",
    "improve the objective function. It is a heuristic, however, so unlike\n",
    "Fisher-Jenks, there is no optimal solution guaranteed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-victor",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp5 = mapclassify.MaxP(mx[\"PCGDP1940\"], k=5)\n",
    "mp5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-folder",
   "metadata": {},
   "source": [
    "### Comparing classification schemes\n",
    "\n",
    "As a special case of clustering, the definition of\n",
    "the number of classes and the class boundaries pose a problem to the map\n",
    "designer. Recall that the Freedman-Diaconis rule was said to be optimal,\n",
    "however; optimality can only be measured relative to a specified objective function.\n",
    "In the case of Freedman-Diaconis, the objective function is to minimize the\n",
    "difference between the area under estimated kernel density based on the sample\n",
    "and the area under the theoretical population distribution that generated the\n",
    "sample. \n",
    "\n",
    "This notion of statistical fit is an important one. However, it is not the\n",
    "only consideration when evaluating classifiers for the purpose of choropleth\n",
    "mapping. Also relevant is the spatial distribution of the attribute values and\n",
    "the ability of the classifier to convey a sense of that spatial distribution. As\n",
    "we shall see, this is not necessarily directly related to the statistical\n",
    "distribution of the attribute values. We will return to a joint consideration of both\n",
    "the statistical and spatial distribution of the attribute values when comparing classifiers\n",
    "later in this chapter. \n",
    "\n",
    "For map classification, a common optimality criterion\n",
    "is a measure of fit. In `mapclassify`, the absolute deviation around class\n",
    "medians (ADCM) is calculated and provides a measure of fit that allows for\n",
    "comparison of alternative classifiers for the same value of $k$. The ADCM\n",
    "will give us a sense of how \"compact\" each group is. To see this, we can\n",
    "compare different classifiers for $k=5$ on the Mexico data in Figure 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-impression",
   "metadata": {
    "caption": "Absolute Deviation around Class Medians. Alternative classification schemes, Mexican state per capita GDP in 1940.",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bunch classifier objects\n",
    "class5 = q5, ei5, ht, mb5, msd, fj5, jc5, mp5\n",
    "# Collect ADCM for each classifier\n",
    "fits = numpy.array([c.adcm for c in class5])\n",
    "# Convert ADCM scores to a DataFrame\n",
    "adcms = pandas.DataFrame(fits)\n",
    "# Add classifier names\n",
    "adcms[\"classifier\"] = [c.name for c in class5]\n",
    "# Add column names to the ADCM\n",
    "adcms.columns = [\"ADCM\", \"Classifier\"]\n",
    "ax = seaborn.barplot(\n",
    "    y=\"Classifier\", x=\"ADCM\", data=adcms, palette=\"Pastel1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generous-lambda",
   "metadata": {},
   "source": [
    "As is to be expected, the Fisher-Jenks classifier dominates all other k=5\n",
    "classifiers with an ADCM of 23,729 (remember, lower is better). Interestingly, the equal interval classifier\n",
    "performs well despite the problems associated with being sensitive to the\n",
    "extreme values in the distribution. The mean-standard deviation classifier has a\n",
    "very poor fit due to the skewed nature of the data and the concentrated\n",
    "assignment of the majority of the observations to the central class.\n",
    "\n",
    "The ADCM provides a global measure of fit which can be used to compare the\n",
    "alternative classifiers. As a complement to this global perspective, it can be\n",
    "revealing to consider how each of the observations in our data was classified across\n",
    "the alternative approaches. To do this, we can add the class bin attribute (`yb`)\n",
    "generated by the `mapclassify` classifiers as additional columns in the dataframe to\n",
    "visualize how they map to observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-favor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append class values as a separate column\n",
    "mx[\"Quantiles\"] = q5.yb\n",
    "mx[\"Equal Interval\"] = ei5.yb\n",
    "mx[\"Head-Tail Breaks\"] = ht.yb\n",
    "mx[\"Maximum Breaks\"] = mb5.yb\n",
    "mx[\"Mean-Standard Deviation\"] = msd.yb\n",
    "mx[\"Fisher-Jenks\"] = fj5.yb\n",
    "mx[\"Jenks Caspall\"] = jc5.yb\n",
    "mx[\"MaxP\"] = mp5.yb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-telling",
   "metadata": {},
   "source": [
    "With those in one place, we can display their labels in a heatmap. Note that, since our variable of interest is continuous, we can sort the rows of the table by their value (`.sort_values('PCGDP1940')`) and color each cell according to the label assigned to it by each classifier. To make the heatmap easier to read, we transpose it (`.T`) so that Mexican states are displayed along the horizontal axis and classification schemes are along the vertical one. (see Figure 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-rider",
   "metadata": {
    "caption": "Assignment differences between alternative classification schemes, Mexican state per capita GDP in 1940.",
    "tags": []
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(9, 3))\n",
    "seaborn.heatmap(\n",
    "    mx.set_index(\"NAME\")\n",
    "    .sort_values(\"PCGDP1940\")[\n",
    "        [\n",
    "            \"Head-Tail Breaks\",\n",
    "            \"Fisher-Jenks\",\n",
    "            \"Maximum Breaks\",\n",
    "            \"Equal Interval\",\n",
    "            \"MaxP\",\n",
    "            \"Quantiles\",\n",
    "            \"Jenks Caspall\",\n",
    "            \"Mean-Standard Deviation\",\n",
    "        ]\n",
    "    ]\n",
    "    .T,\n",
    "    cmap=\"YlGn\",\n",
    "    cbar=False,\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_xlabel(\"State ID\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-experiment",
   "metadata": {},
   "source": [
    "Figure 3 can be challenging to read at first but, once you \"decode\" it, it packs\n",
    "a lot of information. Each row includes a full \n",
    "series of all of our data, classified by an algorithm, with the group to which it \n",
    "has been assigned encoded on a color scale from light yellow (lowest value group) \n",
    "to dark green (largest value group). Conversely, each column represents how a given\n",
    "state is classified across the different schemes considered. Inspection of the table\n",
    "reveals a number of interesting results. For example, the\n",
    "only Mexican state that is treated consistently across the k=5 classifiers is\n",
    "Baja California Norte which is placed in the highest class by all classifiers.\n",
    "Additionally, the mean-standard deviation classifier has an empty first class due to\n",
    "the inadmissible upper bound and the over-concentration of values in the central\n",
    "class (2).\n",
    "\n",
    "Finally, we can consider a meso-level view of the classification\n",
    "results by comparing the number of values assigned to each class across the\n",
    "different classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-sector",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.DataFrame(\n",
    "    {c.name: c.counts for c in class5},\n",
    "    index=[\"Class-{}\".format(i) for i in range(5)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-movie",
   "metadata": {},
   "source": [
    "Doing so highlights the similarities between Fisher-Jenks and equal intervals as\n",
    "the distribution counts are very similar, with the two approaches agreeing on all 17\n",
    "states assigned to the first class. Indeed, the only observation that\n",
    "distinguishes the two classifiers is the treatment of Baja California Sur which\n",
    "is kept in class 1 in equal intervals, but assigned to class 2 by Fisher-Jenks.\n",
    "\n",
    "## Color\n",
    "\n",
    "Having considered the evaluation of the statistical distribution of\n",
    "the attribute values and the alternative classification approaches, we turn\n",
    "to select the symbolization and color scheme. Together with the choice \n",
    "of classifier, these will determine the overall\n",
    "effectiveness of the choropleth map in representing the spatial\n",
    "distribution of the attribute values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-president",
   "metadata": {},
   "source": [
    "Prior to examining the attribute values it is important to note that, as we will\n",
    "see in the figures below, the\n",
    "spatial units for these states are far from homogeneous in their shapes and\n",
    "sizes. This can have major impacts on our brain's pattern recognition capabilities,\n",
    "as we tend to be drawn to the larger polygons, even though they might not be\n",
    "the most relevant ones for our analysis. Yet, when we considered the\n",
    "statistical distribution above, each observation was given equal weight. Thus,\n",
    "the spatial distribution becomes more complicated to evaluate from a visual and\n",
    "statistical perspective.\n",
    "\n",
    "The choice of a color scheme for a\n",
    "choropleth map should be based on the type of variable under consideration\n",
    "{cite}`Brewer1997mapping`. Generally, a distinction is drawn between three\n",
    "types of numerical attributes: sequential, diverging, and qualitative. We will\n",
    "dig into each below, but we will explore how we can make choropleths in\n",
    "Python first. The mechanics are the same across different types of data, so it is worth\n",
    "spending a bit of time first to get the general idea.\n",
    "\n",
    "We will illustrate it with a quantile map in Figure 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-musical",
   "metadata": {
    "caption": "Quantile choropleth, Mexican state per capita GDP in 1940.",
    "tags": []
   },
   "outputs": [],
   "source": [
    "ax = mx.plot(\n",
    "    column=\"PCGDP1940\",  # Data to plot\n",
    "    scheme=\"Quantiles\",  # Classification scheme\n",
    "    cmap=\"YlGn\",  # Color palette\n",
    "    legend=True,  # Add legend\n",
    "    legend_kwds={\"fmt\": \"{:.0f}\"},  # Remove decimals in legend\n",
    ")\n",
    "ax.set_axis_off();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earned-baseball",
   "metadata": {},
   "source": [
    "Making choropleths on geo-tables is an extension of plotting their geometries. We use the same `.plot()` function, but now we also select the column of data we want to encode with color (in our case, `PCGDP1940`). We can also specify the classification scheme using the same names as we saw above with `mapclassify`. In fact, the underlying computation is always performed with `mapclassify`. This approach simply dispatches it so it is more convenient and we can make maps in one line of code. Next, we pick the color scheme. The default color map used by `geopandas` is viridis, which is a multi-hue sequential scheme but, for this example, we pick the yellow-to-green scale from Color Brewer. Finally, we specify that we would like to add a legend, and format it for legibility so that there are no decimals and it reads cleaner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-membrane",
   "metadata": {},
   "source": [
    "### Sequential palettes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "included-deadline",
   "metadata": {},
   "source": [
    "Sequential color schemes are appropriate for continuous data where the origin is in one end of the series. The `PCGDP1940` column we have been using so far is a good example. In these cases, we want a palette that encodes this feature in its choice of colors. Sequential palettes use a gradient of colors from an origin color to a destination color. The example above, where lowest values are encoded in the lightest yellow and the highest in dark green is a good one. Sequential palettes can also have a shades of a single color. For example, the popular \"blues\" palette in Color Brewer is a great choice too, shown in Figure 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-content",
   "metadata": {
    "caption": "Quantile choropleth with black borderlines, Mexican state per capita GDP in 1940.",
    "tags": []
   },
   "outputs": [],
   "source": [
    "ax = mx.plot(\n",
    "    column=\"PCGDP1940\",  # Data to plot\n",
    "    scheme=\"Quantiles\",  # Classification scheme\n",
    "    cmap=\"Blues\",  # Color palette\n",
    "    edgecolor=\"k\",  # Borderline color\n",
    "    linewidth=0.1,  # Borderline width\n",
    "    legend=True,  # Add legend\n",
    "    legend_kwds={\n",
    "        \"fmt\": \"{:.0f}\"\n",
    "    },  # Remove decimals in legend (for legibility)\n",
    ")\n",
    "ax.set_axis_off();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-socket",
   "metadata": {},
   "source": [
    "Note how, in this case, we switch borderlines to black so that we can distinguish states in the lowest category from the white background."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-router",
   "metadata": {},
   "source": [
    "### Diverging palettes\n",
    "\n",
    "A slightly different pallete from the sequential one is the so-called \"diverging\" values palette. This is\n",
    "useful with continuous data when one wishes to place equal emphasis on mid-range critical values as\n",
    "well as extremes at both ends of the distribution. Light colors are used to\n",
    "emphasize the mid-range class, while dark colors with contrasting hues are used\n",
    "to distinguish the low and high extremes.\n",
    "\n",
    "To illustrate this with the Mexican\n",
    "income data, we can derive a new variable which measures the change in a state's\n",
    "rank in the income distribution from 1940 to 2000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-penalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create income-based rank table (Rank 1 is highest)\n",
    "rnk = mx[[\"NAME\", \"PCGDP1940\", \"PCGDP2000\"]].rank(ascending=False)\n",
    "# Compute change from 1940 to 2000\n",
    "rnk[\"change\"] = rnk[\"PCGDP1940\"] - rnk[\"PCGDP2000\"]\n",
    "# Add column with bin class\n",
    "rnk[\"class\"] = pandas.cut(rnk[\"change\"], [-numpy.inf, -5, 0, 5, 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-contamination",
   "metadata": {},
   "source": [
    "The `rnk` table now contains the change in rank positions of each state between 1940 and 2000, as well as a `class` column that binds together states in the  [-inf, -5), [-5, 0), [0, 5), [5, 20] groups. Note that these are descending ranks, so the wealthiest state in any period has a rank of 1, and therefore when considering the change in ranks, a negative change reflects moving down the income distribution. We can use a divergent palette to signify both intensity of the change in ranks, as well as direction in Figure 6: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-vector",
   "metadata": {
    "caption": "Divergent palette, Mexican state per capita income rank change.",
    "tags": []
   },
   "outputs": [],
   "source": [
    "ax = (\n",
    "    mx[[\"geometry\"]]\n",
    "    .join(rnk)\n",
    "    .plot(\"class\", legend=True, cmap=\"RdYlGn\")\n",
    ")\n",
    "ax.set_axis_off();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-cooler",
   "metadata": {},
   "source": [
    "In the map, the red (green) hues are states that have moved downward (upward) in the\n",
    "income distribution, with the darker hue representing a larger movement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-affiliation",
   "metadata": {},
   "source": [
    "### Qualitative palettes\n",
    "\n",
    "Qualitative palettes encode categorical data. In this case, colors do _not_ follow\n",
    "a gradient but rather imply qualitative differences between classes. That is, observations\n",
    "in one group are not more or less, above or below those in other groups, rather just\n",
    "different.\n",
    "\n",
    "The Mexico data set also has several variables that\n",
    "are on a nominal measurement scale. One of these is a region definition variable\n",
    "that groups individual states in contiguous clusters of similar characteristics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-perry",
   "metadata": {},
   "outputs": [],
   "source": [
    "mx[\"HANSON98\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-victim",
   "metadata": {},
   "source": [
    "This aggregation scheme partitions Mexico into five regions, recorded with\n",
    "the numbers 1 to 5 in the table. A naive (and\n",
    "incorrect) way to display this would be to treat the region variable as\n",
    "sequential, visualized in Figure 7: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-encyclopedia",
   "metadata": {
    "caption": "(Incorrect) sequential palette, Mexican regions.",
    "tags": []
   },
   "outputs": [],
   "source": [
    "ax = mx.plot(\"HANSON98\")\n",
    "ax.set_axis_off();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generous-poker",
   "metadata": {},
   "source": [
    "This is not correct because the region variable is not on an interval scale, so\n",
    "the differences between the values have no quantitative significance, but rather\n",
    "the values simply indicate region membership. However, the choropleth in Figure 7 gives\n",
    "a clear visual cue that regions in the south have larger values\n",
    "than those in the north, as the color map implies an intensity gradient.\n",
    "\n",
    "A more appropriate visualization\n",
    "is to use a \"qualitative\" color palette, which is used if you specify that\n",
    "the variable is categorical (Figure 8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-ebony",
   "metadata": {
    "caption": "Qualitative palette, Mexican regions.",
    "tags": []
   },
   "outputs": [],
   "source": [
    "ax = mx.plot(\"HANSON98\", categorical=True, legend=True)\n",
    "ax.set_axis_off();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-listing",
   "metadata": {},
   "source": [
    "## Advanced topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-cedar",
   "metadata": {},
   "source": [
    "### User-defined choropleths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-anaheim",
   "metadata": {},
   "source": [
    "In this last section of the chapter, we consider bespoke partitions of the data that do not follow any particular algorithm but instead are informed by, for example, domain knowledge. Consider the case of classifying income in a policy context. Imagine we wanted to explore the distribution of areas with less than $\\$$10,000, then those between $\\$$10,000 and $\\$$12,500; $\\$$12,500 and $\\$$15,000; and greater than $\\$$15,000. These boundaries are arbitrary but may be tied to specific policies in which the first group is targetted in one particular way, the second and third in different ways, and the fourth is not part of the policy, for example.\n",
    "\n",
    "To create a choropleth that reflects this partitioning of the data, we can use the `UserDefined` classifier in `mapclassify`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-pulse",
   "metadata": {},
   "outputs": [],
   "source": [
    "classi = mapclassify.UserDefined(\n",
    "    mx[\"PCGDP2000\"], [10000, 12500, 15000]\n",
    ")\n",
    "classi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finished-bumper",
   "metadata": {},
   "source": [
    "If we now want to display these classes on a map, we can use a similar approach to how we have seen above, or use the built-in plotting method in `mapclassify` to generate Figure 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-botswana",
   "metadata": {
    "caption": "Choropleth map colored to focus on areas of southern Mexico eligible for a target policy, showcasing user-defined map classifications.",
    "tags": []
   },
   "outputs": [],
   "source": [
    "classi.plot(\n",
    "    mx,  # Use geometries in the geo-table\n",
    "    legend=True,  # Add a legend\n",
    "    legend_kwds={\n",
    "        \"loc\": \"upper right\"\n",
    "    },  # Place legend on top right corner\n",
    "    axis_on=False,  # Remove axis\n",
    "    cmap=\"viridis_r\",  # Use reverse Viridis\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-birmingham",
   "metadata": {},
   "source": [
    "Since we want to draw attention to the classes at the bottom of the scale, we use the reverse viridis (`viridis_r`) palette. Thus, Figure 9 shows in purple the areas not targeted by our hypothetical policy.\n",
    "\n",
    "The approach above is useful in that it is based on `mapclassify` and thus provides a unified interface shared with all the algorithms seen above. An alternative one involves using the `pandas.cut` method, which allows us to easily include a legend too in Figure 10: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-growing",
   "metadata": {
    "caption": "User-defined palette, `pandas` approach.",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Classify values specifying bins\n",
    "lbls = pandas.cut(\n",
    "    mx[\"PCGDP2000\"], [-numpy.inf, 10000, 12500, 15000, numpy.inf]\n",
    ")\n",
    "# Dynamically assign to geo-table and plot with a legend\n",
    "ax = mx.plot(lbls, cmap=\"viridis_r\", legend=True)\n",
    "# Remove axis\n",
    "ax.set_axis_off();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-genealogy",
   "metadata": {},
   "source": [
    "### Pooled classifications\n",
    "\n",
    "Sometimes choropleths exist as part of larger figures that may include more choropleths. In some cases, each of them can be best considered as an independent map, and then everything we have seen so far applies directly. In other instances, we may want to create a single classification of values _across_ the maps and use it consistently. For those situations, we can create _pooled_ classifications that consider all the values across the series.\n",
    "\n",
    "To illustrate this approach, we will create a figure with choropleths of GDP per capita in 1940, 1960, 1980, and 2000; and we will use the same classification across the four maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-glory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the years we want of pc GDP\n",
    "years = [\"PCGDP1940\", \"PCGDP1960\", \"PCGDP1980\", \"PCGDP2000\"]\n",
    "# Create pooled classification\n",
    "pooled = mapclassify.Pooled(mx[years], classifier=\"Quantiles\", k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-corporation",
   "metadata": {},
   "source": [
    "The `pooled` object contains a lot of information on the classification and we can use it to generate a figure with the maps. To do that, we rely also on the `UserDefined` classifier we have just seen in the previous section to create a multi-pane figure showing the per capita income as it changes over time (Figure 11). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-scroll",
   "metadata": {
    "caption": "Pooled quantile classification of per capita GDP for 1940, 1960, 1980, and 2000, Mexican states.",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up figure with four axis\n",
    "f, axs = plt.subplots(2, 2, figsize=(12, 12))\n",
    "# Flatten the array of axis so you can loop over\n",
    "# in one dimension\n",
    "axs = axs.flatten()\n",
    "# Loop over each year\n",
    "for i, y in enumerate(years):\n",
    "    mx.plot(\n",
    "        y,  # Year to plot\n",
    "        scheme=\"UserDefined\",  # Use our own bins\n",
    "        classification_kwds={\n",
    "            \"bins\": pooled.global_classifier.bins\n",
    "        },  # Use global bins\n",
    "        legend=True,  # Add a legend\n",
    "        ax=axs[i],  # Plot on the corresponding axis\n",
    "    )\n",
    "    # Remove axis\n",
    "    axs[i].set_axis_off()\n",
    "    # Name the subplot with the name of the column\n",
    "    axs[i].set_title(y)\n",
    "# Tight layout to better use space\n",
    "plt.tight_layout()\n",
    "# Display figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-invalid",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this chapter we have considered the construction of choropleth maps for\n",
    "spatial data visualization. The key issues of the choice of classification\n",
    "scheme, variable measurement scale, spatial configuration and color palettes\n",
    "were illustrated using Pysal's map classification module together with other\n",
    "related packages in the Python data stack.\n",
    "\n",
    "Choropleth maps are a central tool in the geographic data science toolkit, as\n",
    "they provide powerful visualizations of the spatial distribution of attribute\n",
    "values. We have only touched on the basic concepts in this chapter, as there is\n",
    "much more that can be said about cartographic theory and the design of effective\n",
    "choropleth maps. Readers interested in pursuing this literature are encouraged\n",
    "to see the references cited.\n",
    "\n",
    "At the same time, given the philosophy underlying Pysal, the methods we cover\n",
    "here are sufficient for exploratory data analysis where the rapid and flexible\n",
    "generation of views is critical to the work flow. Once the analysis is complete,\n",
    "and the final presentation quality maps are to be generated, there are excellent\n",
    "packages in the data stack that the user can turn to.\n",
    "\n",
    "## Questions\n",
    "\n",
    "1. A variable (such as population density measured for census tracts in a metropolitan area) can display a high degree of skewness. That is, the distribution may be very asymmetric, either with a few very high values and a bulk of low ones; or a few very low values with a bulk of high values. What is an appropriate choice for a choropleth classification for a skewed variable?\n",
    "2. Provide two solutions to the problem of ties when applying quantile classification to the following series: $y=[2,2,2,2,2,2,4,7,8,9,20,21]$ and $k=4$. Discuss the merits of each approach.\n",
    "3. Which classifiers are appropriate for data that displays a high degree of multi-modality in its statistical distribution? \n",
    "4. Are there any colormaps that work well for multi-modal data?\n",
    "5. Contrast and compare classed choropleth maps with class-less (i.e., continuous-scale) choropleth maps? What are the strengths and limitations of each type of visualization for spatial data?\n",
    "6. In what ways do choropleth classifiers treat intra-class and inter-class heterogeneity differently? What are the implications of these choices?\n",
    "7. To what extent do most commonly employed choropleth classification methods take the geographical distribution of the variable into consideration? Can you think of ways to incorporate the spatial features of a variable into a classification for a choropleth map?\n",
    "8. Discuss the similarities between the choice of the number of classes in choropleth mapping, on the one hand, and the determination of the number of clusters in a data set on the other. What aspects of choropleth mapping differentiate the former from the latter?\n",
    "9. The Fisher-Jenks classifier will always have more internally homogeneous classes than other k-classifiers. Given this, why might one decide on choosing a different k-classifier for a particular data set?\n",
    "\n",
    "## Next steps\n",
    "\n",
    "We have but touched the surface of the large literature on choropleth mapping in particular, and geovisualization more generally. Readers interested in delving deeper into these topices are directed to the following:\n",
    "\n",
    "- {cite}`slocum2014thematic`. Thematic Cartography and Geovisualization. Pearson.\n",
    "- {cite}`cromely2009choropleth`. \"Choropleth map legend design for visualizing community health disparities.\" *International Journal of Health Geographics*, 8: 1-11.\n",
    "- {cite}`cromely1996comparison`. \"A comparison of optimal classification strategies for choroplethic displays of spatiall aggregated data.\" *International Journal of Geographc Information Systems*, 10: 405-424.\n",
    "- {cite}`brewer2005designming`. Designing better maps: A guide for GIS Users. ESRI press.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-acquisition",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
